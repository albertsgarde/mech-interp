defaults:
  - mas
  - _self_

params:
  high_activation_weighting: 4.0
  firing_threshold: 0.5
  sample_overlap: 256
  num_max_samples: 32
  sample_length_pre: 192
  sample_length_post: 64
  samples_to_check: 32
  seed: 0
  activation_bins:
    ranges:
      - start: 0.0
        end: 6.0
        num_bins: 31

dataset_name: 'Skylion007/openwebtext'
model_name: 'gpt2-small'
layers:
  - hook_id: blocks.0.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.1.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.2.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.3.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.4.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.5.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.6.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.7.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.8.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.9.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.10.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.11.mlp.hook_post
    num_features: 3072
  - hook_id: blocks.0.mlp.hook_post
    sae_oai_layer: 0
  - hook_id: blocks.1.mlp.hook_post
    sae_oai_layer: 1
  - hook_id: blocks.2.mlp.hook_post
    sae_oai_layer: 2
  - hook_id: blocks.3.mlp.hook_post
    sae_oai_layer: 3
  - hook_id: blocks.4.mlp.hook_post
    sae_oai_layer: 4
  - hook_id: blocks.5.mlp.hook_post
    sae_oai_layer: 5
  - hook_id: blocks.6.mlp.hook_post
    sae_oai_layer: 6
  - hook_id: blocks.7.mlp.hook_post
    sae_oai_layer: 7
  - hook_id: blocks.8.mlp.hook_post
    sae_oai_layer: 8
  - hook_id: blocks.9.mlp.hook_post
    sae_oai_layer: 9
  - hook_id: blocks.10.mlp.hook_post
    sae_oai_layer: 10
  - hook_id: blocks.11.mlp.hook_post
    sae_oai_layer: 11
out_path: outputs/gpt2-small_sae_store
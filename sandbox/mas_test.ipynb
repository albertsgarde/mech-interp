{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import datasets  # type: ignore[missingTypeStubs, import-untyped]\n",
                "import torch\n",
                "from datasets import IterableDataset  # type: ignore[missingTypeStubs]\n",
                "from transformer_lens.HookedTransformer import HookedTransformer  # type: ignore[import]\n",
                "\n",
                "from mechint import hooks\n",
                "from mechint.device import get_device  # type: ignore[import]\n",
                "from mechint.mas import algorithm, html\n",
                "from mechint.mas.algorithm import MASLayer, MASParams"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded pretrained model gelu-1l into HookedTransformer\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9eee955db0a04b908f9a147c4a85d617",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n",
                        "Model context size: 1024\n",
                        "0%\n",
                        "1%\n",
                        "2%\n",
                        "3%\n",
                        "4%\n",
                        "5%\n",
                        "6%\n",
                        "7%\n",
                        "8%\n",
                        "9%\n",
                        "10%\n",
                        "11%\n",
                        "12%\n",
                        "13%\n",
                        "14%\n",
                        "15%\n",
                        "16%\n",
                        "17%\n",
                        "18%\n",
                        "19%\n",
                        "20%\n",
                        "21%\n",
                        "22%\n",
                        "23%\n",
                        "24%\n",
                        "25%\n",
                        "26%\n",
                        "27%\n",
                        "28%\n",
                        "29%\n",
                        "30%\n",
                        "31%\n",
                        "32%\n",
                        "33%\n",
                        "34%\n",
                        "35%\n",
                        "36%\n",
                        "37%\n",
                        "38%\n",
                        "39%\n",
                        "40%\n",
                        "41%\n",
                        "42%\n",
                        "43%\n",
                        "44%\n",
                        "45%\n",
                        "46%\n",
                        "47%\n",
                        "48%\n",
                        "49%\n",
                        "50%\n",
                        "51%\n",
                        "52%\n",
                        "53%\n",
                        "54%\n",
                        "55%\n",
                        "56%\n",
                        "57%\n",
                        "58%\n",
                        "59%\n",
                        "60%\n",
                        "61%\n",
                        "62%\n",
                        "63%\n",
                        "64%\n",
                        "65%\n",
                        "66%\n",
                        "67%\n",
                        "68%\n",
                        "69%\n",
                        "70%\n",
                        "71%\n",
                        "72%\n",
                        "73%\n",
                        "74%\n",
                        "75%\n",
                        "76%\n",
                        "77%\n",
                        "78%\n",
                        "79%\n",
                        "80%\n",
                        "81%\n",
                        "82%\n",
                        "83%\n",
                        "84%\n",
                        "85%\n",
                        "86%\n",
                        "87%\n",
                        "88%\n",
                        "89%\n",
                        "90%\n",
                        "91%\n",
                        "92%\n",
                        "93%\n",
                        "94%\n",
                        "95%\n",
                        "96%\n",
                        "97%\n",
                        "98%\n",
                        "99%\n",
                        "Time taken: 473.43s\n",
                        "Time taken per sample: 115.58ms\n",
                        "Model time: 47.49s (10.03%)\n",
                        "MAS time: 407.87s (86.15%)\n"
                    ]
                }
            ],
            "source": [
                "params = MASParams(\n",
                "    sample_overlap=128, num_max_samples=16, sample_length_pre=96, sample_length_post=32, samples_to_check=4096\n",
                ")\n",
                "\n",
                "device = get_device()\n",
                "\n",
                "model: HookedTransformer = HookedTransformer.from_pretrained(\"gelu-1l\", device=device.torch())  # type: ignore[reportUnknownVariableType]\n",
                "\n",
                "dataset: IterableDataset = datasets.load_dataset(  # type: ignore[reportUnknownMemberType]\n",
                "    \"monology/pile-uncopyrighted\", streaming=True, split=\"train\", trust_remote_code=True\n",
                ")\n",
                "\n",
                "hook_point = \"blocks.0.mlp.hook_post\"\n",
                "layers = [MASLayer.from_hook_id(hook_point, 2048)]\n",
                "\n",
                "mas_store = algorithm.run(model, dataset, layers, params, device)\n",
                "\n",
                "mas_samples = mas_store.feature_samples()\n",
                "mas_activations = mas_store.feature_activations()\n",
                "\n",
                "assert mas_samples.shape == (2048, 16, 128)\n",
                "assert mas_activations.shape == (2048, 16, 128)\n",
                "\n",
                "assert mas_samples.isfinite().all()\n",
                "assert mas_activations.isfinite().all()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "indices = [423, 512, 1502, 30]\n",
                "\n",
                "for index in indices:\n",
                "    output_dir = Path(\"outputs\") / \"mas_test\"\n",
                "    output_dir.mkdir(parents=True, exist_ok=True)\n",
                "    with open(output_dir / f\"mas_{index}.html\", \"w\") as f:\n",
                "        f.write(html.generate_html(model, mas_samples[index], mas_activations[index]))\n",
                "    activations = hooks.neuron_activations(model, hook_point, mas_samples[index], index, device)\n",
                "    with open(output_dir / f\"{index}.html\", \"w\") as f:\n",
                "        f.write(html.generate_html(model, mas_samples[index], activations))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[99, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [94, 96],\n",
                        "        [96, 96],\n",
                        "        [94, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [99, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96]], device='cuda:0')\n",
                        "tensor([[ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 30,  96],\n",
                        "        [ 96,  96],\n",
                        "        [125,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 87,  96],\n",
                        "        [ 96,  96],\n",
                        "        [ 69,  96]], device='cuda:0')\n",
                        "tensor([[99, 96],\n",
                        "        [95, 96],\n",
                        "        [96, 96],\n",
                        "        [32, 32],\n",
                        "        [48, 48],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [19, 19],\n",
                        "        [96, 96],\n",
                        "        [96, 96],\n",
                        "        [71, 71],\n",
                        "        [96, 96]], device='cuda:0')\n"
                    ]
                }
            ],
            "source": [
                "for i in indices:\n",
                "    activations = hooks.neuron_activations(model, hook_point, mas_samples[i, :, :], i, device)\n",
                "    if (activations.argmax(dim=1) != mas_activations[i].argmax(dim=1)).any():\n",
                "        print(\"Neuron: {i}\")\n",
                "        print(torch.stack((activations.argmax(dim=1), mas_activations[i].argmax(dim=1)), dim=1))\n",
                "        print(model.to_str_tokens)\n",
                "        break"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "deepdecipher",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'n2g.neuron_model' from 'C:\\\\Users\\\\alber\\\\Documents\\\\Neuron2Graph\\\\n2g\\\\neuron_model.py'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import n2g\n",
    "import torch\n",
    "import transformer_lens  # type: ignore[import]\n",
    "from jaxtyping import Float, Int\n",
    "from n2g import NeuronStats, Tokenizer\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint  # type: ignore[import]\n",
    "\n",
    "from thesis.device import Device\n",
    "from thesis.mas.mas_store import MASStore\n",
    "from thesis.sae.sae import SparseAutoencoder\n",
    "from thesis.mas import html\n",
    "\n",
    "importlib.reload(n2g)\n",
    "importlib.reload(n2g.fit)\n",
    "importlib.reload(n2g.neuron_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-1l into HookedTransformer\n",
      "feature_index=0\n",
      "Num train samples: 16\n",
      "Processing 1 of 16\n",
      "tensor([185])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 6\n",
      "Processing 2 of 16\n",
      "tensor([190])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 3 of 16\n",
      "tensor([18])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 4 of 16\n",
      "tensor([243])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 5 of 16\n",
      "tensor([218])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 6\n",
      "Processing 6 of 16\n",
      "tensor([164])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 21\n",
      "Processing 7 of 16\n",
      "tensor([130])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 11\n",
      "Processing 8 of 16\n",
      "tensor([94])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 16\n",
      "Processing 9 of 16\n",
      "tensor([255])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 10 of 16\n",
      "tensor([193])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 11 of 16\n",
      "tensor([153])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 6\n",
      "Processing 12 of 16\n",
      "tensor([13])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 13 of 16\n",
      "tensor([13])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 6\n",
      "Processing 14 of 16\n",
      "tensor([74])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 15 of 16\n",
      "tensor([70])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 1\n",
      "Processing 16 of 16\n",
      "tensor([193])\n",
      "num_pruned_results: 1\n",
      "num augmented samples: 26\n",
      "num total samples: 106\n",
      "num_total_lines: 0\n",
      "num_lines_estimate: 0\n",
      "all_lines: []\n",
      "Fitted model\n"
     ]
    }
   ],
   "source": [
    "FEATURES: list[int] = [0]\n",
    "\n",
    "device = Device.get()\n",
    "\n",
    "mas_store = MASStore.load(Path(\"outputs/models/gelu-1l-sae_store.zip\"), device)\n",
    "\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gelu-1l\", device.torch())\n",
    "sae = SparseAutoencoder.from_hf(\"NeelNanda/sparse_autoencoder\", \"25.pt\", \"blocks.0.mlp.hook_post\", device)\n",
    "\n",
    "tokenizer = Tokenizer(model)\n",
    "\n",
    "assert mas_store.feature_samples().shape[0] == 2048 * 9\n",
    "\n",
    "\n",
    "def feature_samples(feature_index: int) -> Tuple[list[str], float]:\n",
    "    store_index = FEATURES[feature_index] + 2048\n",
    "\n",
    "    samples = mas_store.feature_samples()[store_index, :, :]\n",
    "    max_activation = mas_store.feature_max_activations()[store_index, :].max().item()\n",
    "\n",
    "    tokens = [\"\".join(model.tokenizer.batch_decode(sample, clean_up_tokenization_spaces=False)) for sample in samples]\n",
    "\n",
    "    return tokens, max_activation\n",
    "\n",
    "\n",
    "with open(\"test.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    html_str = html.generate_html(\n",
    "        model, mas_store.feature_samples()[2048, :, :], mas_store.feature_activations()[2048, :, :]\n",
    "    )\n",
    "    f.write(html_str)\n",
    "\n",
    "\n",
    "def model_feature_activation(\n",
    "    model: HookedTransformer, layer_id: str, neuron_index: int\n",
    ") -> Callable[[Int[Tensor, \"num_samples sample_length\"]], Float[Tensor, \"num_samples sample_length\"]]:\n",
    "    def result(samples: Int[Tensor, \"num_samples sample_length\"]) -> Float[Tensor, \"num_samples sample_length\"]:\n",
    "        activations: Float[Tensor, \"num_samples sample_length\"] = torch.full(samples.shape, float(\"nan\"))\n",
    "\n",
    "        def hook(activation: Float[Tensor, \"num_samples sample_length neurons_per_layer\"], hook: HookPoint) -> None:\n",
    "            activations[:] = activation[:, :, neuron_index]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.run_with_hooks(samples, fwd_hooks=[(layer_id, hook)])\n",
    "            assert not torch.isnan(activations).any(), \"Activations should not contain NaNs\"\n",
    "\n",
    "        return activations\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def feature_activation(\n",
    "    feature_index: int,\n",
    ") -> Callable[[Int[Tensor, \"num_samples sample_length\"]], Float[Tensor, \"num_samples sample_length\"]]:\n",
    "    return lambda samples: sae.feature_activations(model, samples, FEATURES[feature_index])\n",
    "\n",
    "\n",
    "with Path(\"thesis/n2g/word_to_casings.json\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "    word_to_casings = json.load(f)\n",
    "\n",
    "train_config = n2g.TrainConfig(\n",
    "    n2g.fit.FitConfig(n2g.fit.PruneConfig(batch_size=1), n2g.fit.ImportanceConfig(), n2g.fit.AugmentationConfig())\n",
    ")\n",
    "\n",
    "samples = feature_samples(0)[0]\n",
    "tokenizer = n2g.Tokenizer(model)\n",
    "tokens, str_tokens = tokenizer.batch_tokenize_with_str(samples, True)\n",
    "tokens_non_bos, str_tokens = tokenizer.batch_tokenize_with_str(samples, False)\n",
    "activations = sae.feature_activations(model, mas_store.feature_samples()[2048, :, :], 0)\n",
    "tokenized_activations = sae.feature_activations(model, tokens, 0)\n",
    "tokenized_activations_non_bos = sae.feature_activations(model, tokens_non_bos, 0)\n",
    "mas_activations = mas_store.feature_activations()[2048, :, :]\n",
    "\n",
    "with open(\"test2.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    html_str = html.generate_html(model, mas_store.feature_samples()[2048, :, :], mas_activations)\n",
    "    f.write(html_str)\n",
    "\n",
    "with open(\"test3.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    html_str = html.generate_html(model, mas_store.feature_samples()[2048, :, :], activations)\n",
    "    f.write(html_str)\n",
    "\n",
    "with open(\"test4.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    html_str = html.generate_html(model, tokens, tokenized_activations)\n",
    "    f.write(html_str)\n",
    "\n",
    "with open(\"test5.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    html_str = html.generate_html(model, tokens_non_bos, tokenized_activations_non_bos)\n",
    "    f.write(html_str)\n",
    "\n",
    "\n",
    "stats: list[NeuronStats]\n",
    "models, stats = n2g.run_layer(\n",
    "    len(FEATURES), feature_activation, feature_samples, tokenizer, word_to_casings, device.torch(), train_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n  ', ' cf', '_', 'en', 'viron', '.', 'execute', '()', '\\n   ', '\\n  ']\n",
      "\n",
      "   cf.insert_link( \"link_3\",  \"One_Step\",       [ sprinkler_element.check_for_excessive_flow_rate ] )\n",
      "   cf.insert_link( \"link_3\",  \"Code\",           [ sprinkler_element.monitor ] )\n",
      "   cf.insert_link( \"link_4\",  \"SendEvent\",      [\"CELL_DONE\"] ) \n",
      "   cf.insert_link( \"link_5\",  \"Disable_Chain\",  [[\"monitor_irrigation_cell\",\"monitor_current_sub\" ]])\n",
      "\n",
      "\n",
      "   length = redis.llen(\"QUEUES:SPRINKLER:IRRIGATION_CELL_QUEUE\" )\n",
      "   \n",
      "   cf_environ = py_cf.Execute_Cf_Environment( cf )\n",
      "   cf_environ.execute()\n",
      "   \n",
      "  \n",
      "\n",
      "       \n",
      "     \n",
      "\n",
      "      \n",
      "\n",
      "<|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|><|PAD|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(13, device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 185\n",
    "sample = feature_samples(0)[0][0]\n",
    "tokenizer = n2g.Tokenizer(model)\n",
    "tokens, str_tokens = tokenizer.tokenize_with_str(sample, True)\n",
    "print(str_tokens[index - 5 : index + 5])\n",
    "# feature_samples(0)[0]#[index]\n",
    "print(sample)\n",
    "\n",
    "feature_activation(0)(tokens).argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"8pt\" height=\"8pt\"\n",
       " viewBox=\"0.00 0.00 8.00 8.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 4)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-4 4,-4 4,4 -4,4\"/>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x215ca87bc50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].graphviz()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdecipher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
